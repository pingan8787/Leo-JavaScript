今天 Chris 忙了一下午，没来得及看火山引擎的发布会，因此一下班回家就赶紧搜索相关内容，整理本文和大家分享～还请点个免费的“赞”和“在看”支持一下哈。

正文如下：

今天豆包大模型家族又迎来 3 位新成员，包括**视频生成模型**、**音乐模型**和**同声传译模型**等，真的热闹起来了！

![](https://cdn.nlark.com/yuque/0/2024/png/186051/1727183258647-4bdf7e14-25f1-4653-b361-78bc429942e7.png)目前豆包大模型家族已经包括 12 位成员了，包括：豆包通用模型 pro、豆包通用模型 lite、视频生成模型、文生图模型、图生图模型、同声传译模型、语言识别模型、语音合成模型等等。

> 详细介绍：[https://www.volcengine.com/product/doubao](https://www.volcengine.com/product/doubao)

接下来一起了解下今天新来的 3 为豆包新成员：

## 一、视频生成模型

今天发布的视频生成模型包括：

1. PixelDance 模型；
2. Seaweed 模型；

接下来详细介绍下：

### 1.PixelDance 模型

PixelDance 模型支持**文生视频**和**图生视频**，可生成长达 10 秒视频片段且语义理解能力出色。它能完成时序性多拍动作、支持多主体复杂交互，运镜效果丰富、兼容性强，可应用于影视创作、广告传媒等多个场景。

核心功能如下：

1. **精准的语义理解**：语义理解精准，支持复杂提示词，时序性多拍动作指令与多主体交互能力。
2. **强大动态与炫酷运镜并存**：动作灵动、镜头多样、表情丰富、细节丰满，支持超多镜头语言。
3. **一致性多镜头生成**：一键生成故事性多镜头短片能力，一个提示词实现多个镜头切换并保持主体、风格、氛围一致。
4. **多风格、多比例兼容**：提升视频生成泛化能力，支持包括黑白、2/3D 动画、国画、水彩等多种风格，包含 1:1、3:4、4:、16:9、9:16、21:9 六个比例。

### 2.Seaweed 模型

Seaweed 模型支持**文生视频**和**图生视频**两种方式，基于 **Transformer 结构**在潜空间训练，原生支持多分辨率生成，默认输出特定参数且可动态延长时长，能够生成**具备丰富的细节层次**的影视即视频，可应用于电商营销、动画教育等广泛的应用场景。

亮点功能如下：

- **逼真度极高**：能够生成影视级的视频，具备丰富的细节层次。
- **视觉美感高**：专业级色彩调和和光影布局，大幅提升画面视觉审美。
- **动态流畅**：运动画面流畅自然，速度快慢符合物理运动机制。

### 3.体验模型

这两个模型目前可以在火山引擎中申请并体验。

> 模型体验：[https://console.volcengine.com/ark/region:ark+cn-beijing/experience/vision](https://console.volcengine.com/ark/region:ark+cn-beijing/experience/vision)

![](https://cdn.nlark.com/yuque/0/2024/png/186051/1727185316284-e63cbee3-716a-4139-950c-af1cb2930521.png)

## 二、音乐模型

**音乐生成模型**可以依据**文本描述或图片**，轻松创作出一首**时长 1 分钟**且包含旋律、歌词和演唱的高品质音乐作品。该模型还支持 **10 余种不同风格和情绪**可供随心选择，极大地降低了音乐创作门槛，非常简单好用。

核心亮点如下：

1. **高品质音乐生成**：生成的歌词更准确、旋律更多样、演唱更真实；
2. **创作门槛低**：支持图片、灵感和写词生成音乐，简单方便；
3. **应用场景多**：比如音乐创作、音乐教育、娱乐产业、广告营销等；

## 三、同声传译模型

**同声传译模型**依托豆包大模型的语音理解能力，实现**高质量**、**低延迟**的**端到端同声翻译**，支持**跨语言同音色翻译**，以及粤、沪等常见方言的识别，适用于会议翻译、线上直播等实时场景。

> 体验地址：[https://console.volcengine.com/ark/region:ark+cn-beijing/experience/voice?type=SI](https://console.volcengine.com/ark/region:ark+cn-beijing/experience/voice?type=SI)

![](https://cdn.nlark.com/yuque/0/2024/png/186051/1727185671933-8cc5e8c2-8ef0-4fad-ada0-2ba566c0201b.png)

核心功能如下：

1. **实时翻译，超低延迟**：具备超低延迟的端到端翻译，实现低时延与高质量的平衡。
2. **自然高质量，超精准翻译**：提供高质量精准翻译，语句流畅自然，接近人类专业口译员水平。
3. **音色克隆，更多使用场景**：支持基于音色克隆的语音翻译和字幕翻译，覆盖更多场景。
4. **丰富的应用场景**：提供超低延时且自然高质量的实时翻译，支持跨语言同音色翻译，可应用于会议论坛、线上直播等场景。

## 总结

今天豆包这 3 位新成员非常给力，虽然目前 Chris 还没能及时体验上，但是还是**非常期待**～国产牛逼。以后可以使用豆包、智谱、通义等国产大模型家族，开发各种产品应用了。
