7月30日，火山引擎在其主办的 FORCE Link AI 创新巡展·厦门站活动上，发布**豆包系列新模型及AI云原生服务升级成果**，包括**豆包·图像编辑模型3.0**、**同声传译模型2.0**，以及**全新升级的豆包大模型1.6系列**，同时推出扣子核心能力开源、企业自有模型托管方案等工具，为企业及开发者构建Agent、落地AI应用提供全栈支持。

![](https://cdn.nlark.com/yuque/0/2025/png/186051/1753876265009-4be23533-45d5-4552-a1c5-d1768a637209.png)

图：火山引擎总裁谭待发布最新豆包模型

## 豆包系列新模型面向企业开放
### 1.豆包·图像编辑模型3.0
针对AI图像编辑中“听不懂指令、误改内容、生成效果差”的痛点，火山引擎推出**豆包·图像编辑模型3.0（SeedEdit 3.0）**。该模型通过强化指令遵循能力、图像保持能力及生成质量，让用户**仅凭自然语言即可完成消除冗余、调整光影、替换元素等操作**，还能实现**风格转换**、**材质变换**、**姿势调整**等创新修图场景。该模型广泛适用于影像创作、广告营销等领域，企业用户可在火山方舟调用其API，个人用户则能通过即梦或豆包app进行体验。

![](https://cdn.nlark.com/yuque/0/2025/png/186051/1753875657397-01a243fd-af89-4ed8-b3ce-5a135fc62d2b.png)

### 2.豆包·同声传译模型2.0
最新发布的豆包·同声传译模型2.0（Seed-LiveInterpret 2.0），突破传统“级联模型”局限，采用全双工框架**将语音延迟从8-10秒降至2-3秒**，实现**文本与语音同步生成**。更支持0样本声音复刻，无需提前录制即可实时生成同音色外语语音，甚至匹配方言口音，大幅提升跨语言沟通沉浸感。

![](https://cdn.nlark.com/yuque/0/2025/png/186051/1753875613182-30f89e5b-824f-4f99-b539-8456ebb96681.png)

### 3.豆包大模型1.6系列升级
豆包大模型1.6系列也进行了升级。其中，极速版Doubao-Seed-1.6-flash模型在保持强大视觉理解能力的同时，**强化了代码、推理、数学等能力**，适配智能巡检、手机助手等大规模商业化场景。该模型TPOT（首Token输出时间）低至10ms，为业界领先；成本上，在0-32k输入文本长度区间（企业最常用），每百万tokens输入仅0.15元、输出1.5元，在客户使用案例中，已实现延迟下降60%、成本降低70%。

![](https://cdn.nlark.com/yuque/0/2025/png/186051/1753875573554-c0d9e93e-e459-4647-ae48-e080fe8e8db5.png)

此外，全模态向量化模型Seed1.6-Embedding**首次实现“文本+图像+视频”混合模态融合检索**，助力企业构建更强大的多模态知识库，在权威测评中包揽多模态全面任务及中文文本的最优成绩。



## 优化AI云原生服务，加速Agent开发落地
为助力Agent端到端开发与落地，火山引擎持续优化AI云原生全栈服务。7月26日，AI Agent开发平台扣子核心能力正式开源，涵盖**一站式可视化开发工具“扣子开发平台（Coze Studio）”**和**全链路管理工具“扣子罗盘（Coze Loop）”**，采用Apache 2.0许可证，用户可在GitHub下载。开源仅三天，Coze Studio星标数破万，Coze Loop星标数超3000。火山引擎为其提供全面支持，企业AI平台HiAgent可调用其能力，云基础产品支持一键部署。

> **Coze Studio：**[**https://github.com/coze-dev/coze-studio**](https://github.com/coze-dev/coze-studio)
>
> **Coze Loop：**[**https://github.com/coze-dev/coze-loop**](https://github.com/coze-dev/coze-loop)
>

![](https://cdn.nlark.com/yuque/0/2025/png/186051/1753875942785-4366785a-be4c-412a-87f5-ccd47a3c185e.png)

针对有模型定制需求的企业，火山引擎依托火山方舟模型单元推出自有模型托管方案。企业无需运维底层GPU资源及复杂配置，即可实现自研模型全托管，享受弹性算力，自主选择部署方式与机型，精准控制时延，且**无需为业务低谷期付费，目前已开放邀测**。

同时，火山方舟升级API体系，推出Responses API。该API具备**原生上下文管理能力**，支持**多轮对话链式管理及文本、图像等多模态数据衔接**，结合缓存能力可降低80%成本；还支持单次请求联动多工具与模型组合响应，将智能助手Agent开发从460行代码、1-2天，缩减至60行代码、1小时，大幅提升效率。

此次系列发布进一步完善了火山引擎AI生态布局，为企业与开发者提供从基础模型到开发工具的全链条支持，加速AI在各行业的落地应用。

![](https://cdn.nlark.com/yuque/0/2025/png/186051/1753876292343-b974433b-5c11-411d-8867-1de7e88c8347.png)

